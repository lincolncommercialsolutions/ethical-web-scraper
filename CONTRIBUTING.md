# Contributing to Ethical Web Scraper

Thank you for your interest in contributing! This project is designed for ethical cybersecurity research.

## Code of Conduct

### Ethical Guidelines

1. **Legal Compliance**: All contributions must comply with applicable laws
2. **Ethical Use**: Features must support ethical research practices
3. **Privacy Respect**: No features that enable privacy violations or unauthorized data collection
4. **Transparency**: All scraping must identify itself clearly
5. **robots.txt Compliance**: Default behavior must respect robots.txt

## How to Contribute

### Reporting Issues

- Use GitHub Issues
- Provide clear description and steps to reproduce
- Include Python version and OS information

### Pull Requests

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Make your changes
4. Test thoroughly
5. Commit with clear messages
6. Push to your fork
7. Open a Pull Request

### Code Standards

- Follow PEP 8 style guide
- Add docstrings to functions
- Include type hints where appropriate
- Update documentation as needed
- Ensure ethical compliance

### Testing

- Test with safe, public domains (example.com, httpbin.org)
- Never test on unauthorized systems
- Verify robots.txt compliance
- Check that delays and rate limiting work correctly

## Feature Requests

We welcome ethical feature suggestions:
- Security analysis improvements
- Additional header checks
- Better reporting formats
- Performance optimizations
- Documentation enhancements

**Not Accepted:**
- Features that bypass security measures
- Tools for aggressive/mass scraping
- Privacy violation capabilities
- Anti-detection measures for unauthorized use

## Questions?

Open an issue for questions or discussion.

Thank you for helping make ethical cybersecurity research better! ðŸ”’
